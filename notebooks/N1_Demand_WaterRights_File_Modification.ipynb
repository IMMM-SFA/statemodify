{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c18b0576-41b9-44a3-9fa2-dc3a40ae6e17",
   "metadata": {},
   "source": [
    "## `statemodify` Quickstarter Notebook #1: Getting Started and Using the DDM and DDR Modification Functions in the San Juan River Basin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bee4894-26ba-4cfa-98a1-94413479cce5",
   "metadata": {},
   "source": [
    "In this series of five notebooks, we demonstrate the functionality of `statemodify` using three of the five subbasins on the West Slope basin in the state of Colorado: Gunnison, San Juan/Dolores, and the Upper Colorado Basin. There are two classes of adjustments offered in `statemodify` that can be used to create alternative future states of the world for the region:  \n",
    "\n",
    "1. Application of multipliers or additives to the original dataset which are sampled from specified bounds using a Latin hypercube sample  \n",
    "\n",
    "2. Complete swap of input data with data generated from an external method\n",
    "\n",
    "Option 1 is applicable to `.ddm` (monthly demand), `.ddr` (water rights), `.eva` (reservoir evaporation), `.res` (reservoir storage).\n",
    "\n",
    "Option 2 is applicable to `.xbm` (monthly streamflow) and `.iwr` (irrigation demand). In `statemodify` we provide a Hidden Markov Model (HMM)-based approach to generate synthetic flows across the basins and tie in irrigation demand to be negatively correlated to increased streamflow. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b2f8b1-1a76-4526-a023-fca493180876",
   "metadata": {},
   "source": [
    "In this first notebook, we will demonstrate now to use the demand (`modify_ddm()`)and water rights (`modify_ddr()`) modification functions in the San Juan River Basin. Demands are projected to increase with the growth of cities and agriculture and water rights will likely change as discussions on changes to the Colorado Compact and re-allocation of water across the Colorado River Basin to promote sustainable development continue.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a51930",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\"> \n",
    "    \n",
    "<b>Tip:</b> When each StateMod file is mentioned, clicking on the name will link the user to the <a href=\"https://opencdss.state.co.us/statemod/latest/doc-user/\">StateMod documentation</a> with more information on that file.       \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4724769-1cd7-4582-8089-72eb9370e19b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 1: Run a Historical Simulation in StateMod for the San Juan Basin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4795b0f-0e8d-4186-8c4f-618b58868780",
   "metadata": {
    "tags": []
   },
   "source": [
    "Before we start on an exploratory modeling journey, you may be first interested in understanding water shortages that the basin has historically experienced. In the container, we have downloaded and compiled StateMod, `statemodify`, and the San Juan dataset from the Colorado's Decision Support System (CDSS) website. We can run a baseline simulation below which takes approximately 4 minutes. In this baseline simulation, we run StateMod over the length of the historical period (105 years) under the assumption that we are starting from current conditions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4b22249-5a13-47a5-81ab-88718b856cad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import pickle\n",
    "from string import Template\n",
    "import subprocess\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import statemodify as stm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab8229a",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> \n",
    "    \n",
    "<b>NOTE</b>: Each simulation in this notebook is run for the length of the historical period (from 1909-2013). If you want to reduce the length of the simulation, navigate to the `.ctl` file and adjust the `iystr` and `iyend` variables. For this notebook, these files are located in: `data/sj2015_StateMod_modified/sj2015_StateMod_modified/StateMod\n",
    "Notebook/sj2015.ctl` and `data/gm2015_StateMod_modified/gm2015_StateMod_modified/StateMod/gm2015.ctl`  \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77d95e75-6737-44f9-98b7-e8936fe854b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# statemod directory\n",
    "statemod_dir = \"/usr/src/statemodify/statemod_gunnison_sjd\"\n",
    "\n",
    "# root directory of statemod data for the target basin\n",
    "root_dir = os.path.join(statemod_dir, \"src\", \"main\", \"fortran\")\n",
    "\n",
    "# home directory of notebook instance\n",
    "home_dir = os.path.dirname(os.getcwd())\n",
    "\n",
    "# path to the statemod executable\n",
    "statemod_exe = os.path.join(root_dir, \"statemod-17.0.3-gfortran-lin-64bit-o3\")\n",
    "\n",
    "# data directory and root name for the target basin\n",
    "data_dir = os.path.join(\n",
    "    home_dir,\n",
    "    \"data\",\n",
    "    \"sj2015_StateMod_modified\",\n",
    "    \"sj2015_StateMod_modified\",\n",
    "    \"StateMod\"\n",
    ")\n",
    "\n",
    "# directory to the target basin input files with root name for the basin\n",
    "basin_path = os.path.join(data_dir, \"sj2015B\")\n",
    "\n",
    "# scenarios output directory\n",
    "scenarios_dir_ddm = os.path.join(data_dir, \"scenarios_ddm\")\n",
    "scenarios_dir_ddr = os.path.join(data_dir, \"scenarios_ddr\")\n",
    "\n",
    "# parquet files output directory\n",
    "parquet_dir_ddm = os.path.join(data_dir, \"parquet_ddm\")\n",
    "parquet_dir_ddr = os.path.join(data_dir, \"parquet_ddr\")\n",
    "\n",
    "# path to ddm and ddr template file\n",
    "ddm_template_file = os.path.join(\n",
    "    home_dir,\n",
    "    \"data\",\n",
    "    \"sj2015B_template_ddm.rsp\"\n",
    ")\n",
    "\n",
    "ddr_template_file = os.path.join(\n",
    "    home_dir,\n",
    "    \"data\",\n",
    "    \"sj2015B_template_ddr.rsp\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4568a7bb-7e35-4c54-9e95-f24f44d7384c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# run statemod\n",
    "subprocess.call([statemod_exe, basin_path, \"-simulate\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2d4be2-4249-439b-943e-95dd3f061d25",
   "metadata": {},
   "source": [
    "Once StateMod has run successfully, we can now extract user shortages from the [`.xdd`](https://opencdss.state.co.us/statemod/latest/doc-user/OutputDescription/521/) output file using the `statemodify` output modification function `convert_xdd()`. We denote a list of user IDs ('2900501','2900519','2900555') who we want to extract shortages for and then these shortages are saved in a compressed Parquet file format that can then be read in as a Pandas dataframe in Python. We can also remove the larger output files once the requested shortages have been extracted and saved. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097557cc-273b-4218-aa66-7341f408a616",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Extract shortages using statemodify convert_xdd() function  \n",
    "\n",
    "# create a directory to store the historical shortages  \n",
    "output_dir = os.path.join(data_dir, \"historic_shortages\")\n",
    "\n",
    "# create a directory to store the new files in if it does not exist\n",
    "output_directory = os.path.join(data_dir, \"historic_shortages\")\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "stm.xdd.convert_xdd(\n",
    "    # path to a directory where output .parquet files should be written\n",
    "    output_path=output_dir,\n",
    "    # whether to abort if .parquet files already exist at the output_path\n",
    "    allow_overwrite=True,\n",
    "    # path, glob, or a list of paths/globs to the .xdd files you want to convert\n",
    "    xdd_files=os.path.join(data_dir, \"*.xdd\"),\n",
    "    # if the output .parquet files should only contain a subset of structure ids, list them here; None for all\n",
    "    id_subset=['2900501','2900519','2900555'],\n",
    "    # how many .xdd files to convert in parallel; optimally you will want 2-4 CPUs per parallel process\n",
    "    parallel_jobs=4,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01247aaa-c0c1-4f92-bfd5-d5d50873b2be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data=pd.read_parquet(os.path.join(output_dir,'sj2015B.parquet'),engine='pyarrow')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76e9af6-307e-4240-b81a-5e0cf2747cfa",
   "metadata": {},
   "source": [
    "Upon inspecting the Parquet file above, we see the contents of the `.xdd` file, including the shortages experienced by the structures that we specified for the length of the historical period."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64feada9-d7ab-4920-8a32-670090b0a985",
   "metadata": {
    "tags": []
   },
   "source": [
    "We can then take these shortages and plot them for our list of users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b20787-1445-4af2-801f-f94b52006ab4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data['shortage_total']=data['shortage_total'].astype(float)\n",
    "data['year']=data['year'].astype(int)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for name, group in data.groupby('structure_id'):\n",
    "    ax.scatter(\n",
    "        group['year'], group['shortage_total'], label=name)\n",
    "\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Shortage (AF)\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7f34c3-58df-4b42-b8c8-9373422754ed",
   "metadata": {},
   "source": [
    "You can look up the names and rights of the users listed above in the `sj2015.ddr` file (found at `data/sj2015_StateMod_modified/sj2015_StateMod_modified/StateMod/sj2015.ddr`). Here, a higher Admin # denotes lower seniority. You'll see that the users chosen here have junior to medium seniority of water rights with varying amounts of water decreed to them. The figure above shows that all users have experienced shortages. User 2900501 has experienced the most frequent shortages respectively, likely due in part to their less senior water right. Generally, we see a higher magnitude of shortages for all users during the 2002 drought.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f8b81a-2b34-4528-a96a-d56bdcff216b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 2a: Modify StateMod Input Files for Exploratory Analyses- Demand Function Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90bbd71e-680e-469a-989a-351150cad8b3",
   "metadata": {
    "tags": []
   },
   "source": [
    "Now that we've run StateMod in baseline mode, the next step shows how we can run it in an exploratory analysis mode. To do this, we need to create some plausible futures and adjust the input files of StateMod to reflect these changes. In this step, we'll demonstrate Option 1 for statemodify adjustments using the [`.ddm`](https://opencdss.state.co.us/statemod/latest/doc-user/InputDescription/417/) file as an example, which involves multiplying the current demand time series for these users by a value in between 0.5 to 1.5. Here we specify the IDs of the users and the bounds from which we want to sample multipliers for the demand. We create 2 alternative states of the world (SOW) using a Latin hypercube sampling (LHS) procedure and store them in the `input_files` directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c425b3-f416-4447-ac95-e8efb00ad5cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# a dictionary to describe what users you want to modify and the bounds for the LHS\n",
    "setup_dict = {\n",
    "    \"ids\": [\"2900501\", \"2900519\",\"2900555\"],\n",
    "    \"bounds\": [0.5, 1.5]\n",
    "}\n",
    "\n",
    "output_directory = output_dir = os.path.join(data_dir, \"input_files\")\n",
    "\n",
    "scenario = \"1\"\n",
    "\n",
    "# the number of samples you wish to generate\n",
    "n_samples = 2\n",
    "\n",
    "# seed value for reproducibility if so desired\n",
    "seed_value = 1\n",
    "\n",
    "# number of rows to skip in file after comment\n",
    "skip_rows = 1\n",
    "\n",
    "# name of field to query\n",
    "query_field = \"id\"\n",
    "\n",
    "# number of jobs to launch in parallel; -1 is all but 1 processor used\n",
    "n_jobs = -1\n",
    "\n",
    "# basin to process\n",
    "basin_name = \"San_Juan\"\n",
    "\n",
    "# generate a batch of files using generated LHS\n",
    "stm.modify_ddm(modify_dict=setup_dict,\n",
    "               query_field=query_field,\n",
    "               output_dir=output_directory,\n",
    "               scenario=scenario,\n",
    "               basin_name=basin_name,\n",
    "               sampling_method=\"LHS\",\n",
    "               n_samples=n_samples,\n",
    "               skip_rows=skip_rows,\n",
    "               n_jobs=n_jobs,\n",
    "               seed_value=seed_value,\n",
    "               template_file=None,\n",
    "               factor_method=\"multiply\",\n",
    "               data_specification_file=None,\n",
    "               min_bound_value=-0.5,\n",
    "               max_bound_value=1.5,\n",
    "               save_sample=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1506e5d5-91d9-44cf-81ff-ae1ad0b42d38",
   "metadata": {},
   "source": [
    "It's helpful to set `save_sample=True` to see the values of the multipliers that we are creating. We see below that in our 1st SOW, we are reducing demand for our users by 30% and then in our 2nd SOW, we are increasing demand for our users by 36%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb711821-eba6-444b-baf9-4ab5f88d9587",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "sample_array=np.load(output_directory+'/ddm_2-samples_scenario-1.npy')\n",
    "sample_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09698f0-fd17-437a-8682-6a0cf640a2f9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 2b: Read in the New Input Files and Run StateMod : Demand Function Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4a996c-d698-4178-b4cb-86616b471df8",
   "metadata": {
    "tags": []
   },
   "source": [
    "Now that we have created the input files, the next step is to run StateMod with the new input files. The file that StateMod uses to configure a simulation is called a [`.rsp`](https://opencdss.state.co.us/statemod/latest/doc-user/InputDescription/41/) file. For this dataset, the configuration file is `sj2015B.rsp`. This file contains the paths of all of the supporting files that StateMod needs to run. We create a template .rsp file (`sj2015B_template_ddm.rsp`) and swap in the path to the two new alternative `.ddm` files that are created. Then we run StateMod for the two scenarios and store the shortages in Parquet file format. Each scenario will take approximately 4 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e303b1d-ac7f-4123-b76d-e1c11d407478",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set realization and sample\n",
    "realization = 1\n",
    "sample = np.arange(0, 2, 1)\n",
    "\n",
    "# read RSP template\n",
    "with open(ddm_template_file) as template_obj:\n",
    "    \n",
    "    # read in file\n",
    "    template_rsp = Template(template_obj.read())\n",
    "\n",
    "    for i in sample:\n",
    "        \n",
    "        # create scenario name\n",
    "        scenario = f\"S{i}_{realization}\"\n",
    "        \n",
    "        # dictionary holding search keys and replacement values to update the template file\n",
    "        d = {\"DDM\": f\"../../input_files/sj2015B_{scenario}.ddm\"}\n",
    "        \n",
    "        # update the template\n",
    "        new_rsp = template_rsp.safe_substitute(d)\n",
    "        \n",
    "        # construct simulated scenario directory\n",
    "        simulated_scenario_dir = os.path.join(scenarios_dir_ddm, scenario)\n",
    "        if not os.path.exists(simulated_scenario_dir):\n",
    "            os.makedirs(simulated_scenario_dir)\n",
    "            \n",
    "        # target rsp file\n",
    "        rsp_file = os.path.join(simulated_scenario_dir, f\"sj2015B_{scenario}.rsp\")\n",
    "        \n",
    "        # write updated rsp file\n",
    "        with open(rsp_file, \"w\") as f1:\n",
    "            f1.write(new_rsp)\n",
    "        \n",
    "        # construct simulated basin path\n",
    "        simulated_basin_path = os.path.join(simulated_scenario_dir, f\"sj2015B_{scenario}\")\n",
    "\n",
    "        # run StateMod\n",
    "        print(f\"Running: {scenario}\")\n",
    "        os.chdir(simulated_scenario_dir)\n",
    "\n",
    "        subprocess.call([statemod_exe, simulated_basin_path, \"-simulate\"])\n",
    "        \n",
    "        #Save output to parquet files \n",
    "        print('creating parquet for ' + scenario)\n",
    "        \n",
    "        output_directory = os.path.join(parquet_dir_ddm+\"/scenario/\"+ scenario)\n",
    "        \n",
    "        if not os.path.exists(output_directory):\n",
    "            os.makedirs(output_directory)\n",
    "        \n",
    "        stm.xdd.convert_xdd(output_path=output_directory,allow_overwrite=False,xdd_files=scenarios_dir_ddm + \"/\"+ scenario + \"/sj2015B_\"+scenario+\".xdd\",id_subset=['2900501','2900519','2900555'],parallel_jobs=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6823ea-c1db-4307-b3b5-e52816b710f2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 2c: Visualize Shortages in New SOWs- Demand Function Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe2605e-83c0-448e-83aa-a610182a6687",
   "metadata": {
    "tags": []
   },
   "source": [
    "Now that we have run our simulations, we can visualize the difference in shortages experienced by the stakeholders in our two SOWs. Let's focus on the user: 2900501, a junior user who experienced the most frequent shortages historically across the stakeholders we looked at. Let's look back at the LHS sample and see that SOW 1 is where we have a decreased demand (0.7 multiplier) and SOW 2 is where we have an increased demand (1.4 multiplier)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c8d406-b4eb-4d7a-8b65-7f01047ba688",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_directory = os.path.join(data_dir, \"input_files\")\n",
    "sample_array = np.load(output_directory+'/ddm_2-samples_scenario-1.npy')\n",
    "sample_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd5ac06-6810-4298-8afc-5ce3f4e1c5fa",
   "metadata": {},
   "source": [
    "Now we can define shortages in the alternative states of the world with respect to the shortages received in the baseline case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7de22c-bce2-4b5a-8766-729b5e24cd34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Read in raw parquet files\n",
    "baseline=pd.read_parquet(data_dir+'/historic_shortages/sj2015B.parquet',engine='pyarrow')\n",
    "SOW_1=pd.read_parquet(parquet_dir_ddm+'/scenario/S0_1/sj2015B_S0_1.parquet',engine='pyarrow')\n",
    "SOW_2=pd.read_parquet(parquet_dir_ddm+'/scenario/S1_1/sj2015B_S1_1.parquet',engine='pyarrow')\n",
    "\n",
    "#Subtract shortages with respect to the baseline\n",
    "subset_df=pd.concat([baseline['year'],baseline['shortage_total'],SOW_1['shortage_total'],SOW_2['shortage_total']],axis=1)\n",
    "subset_df = subset_df.set_axis(['Year', 'Baseline', 'SOW_1','SOW_2'], axis=1)\n",
    "subset_df['Baseline']=subset_df['Baseline'].astype(float)\n",
    "subset_df['SOW_1']=subset_df['SOW_1'].astype(float)\n",
    "subset_df['SOW_2']=subset_df['SOW_2'].astype(float)\n",
    "subset_df['Year']=subset_df['Year'].astype(int)\n",
    "subset_df['SOW_1_diff']=subset_df['SOW_1']-subset_df['Baseline']\n",
    "subset_df['SOW_2_diff']=subset_df['SOW_2']-subset_df['Baseline']\n",
    "\n",
    "\n",
    "#Plot shortages\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.scatter(subset_df['Year'], subset_df['SOW_1_diff'],label='Decreased Demand')\n",
    "ax.scatter(subset_df['Year'], subset_df['SOW_2_diff'],label='Increased Demand')\n",
    "\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Shortage (AF)\")\n",
    "plt.title(\"Change in Shortages from the Baseline\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c23cf3-88b0-49e0-8225-5222ad5f480b",
   "metadata": {},
   "source": [
    "As expected, we see that an increase in demand typically causes an increase in shortage magnitude and frequency whereas the reduction in demand leads to the opposite. This finishes our simple example to demonstrate how adjustments to demand might change the shortages experienced by a user. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e20fe5-f977-49db-980d-179cd7e4f278",
   "metadata": {},
   "source": [
    "### Step 3a: Modify StateMod Input Files for Exploratory Analyses- Water Rights Function Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561a26d5-280d-4fb2-b121-e204f27a7d75",
   "metadata": {},
   "source": [
    "Following from Step 2, we can run the same analysis for the function that manipulates the `sj2015.ddr` file, which corresponds to users water rights. In this function, we can specify the IDs of the users and can can utilize a variety of options for how we want to change the [`.ddr`](https://opencdss.state.co.us/statemod/latest/doc-user/InputDescription/46/) file. We can either sample from some bounds that apply multipliers to the decree, hard code in values for the decree, or adjust the rank of the user. In this simple example, we take a very junior user, ID: 2900501, and make them have the highest water right by changing their rank to 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a05136d-2234-45b3-ad26-211664fef29a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# a dictionary to describe what you want to modify and the bounds for the LHS\n",
    "setup_dict = {\n",
    "    # ids can either be 'struct' or 'id' values\n",
    "    \"ids\": [\"2900501\"],\n",
    "\n",
    "    # turn id on or off completely or for a given period\n",
    "    # if 0 = off, 1 = on, YYYY = on for years >= YYYY, -YYYY = off for years > YYYY; see file header\n",
    "    \"on_off\": [1],\n",
    "\n",
    "    # apply rank of administrative order where 0 is lowest (senior) and n is highest (junior); None is no change\n",
    "    \"admin\": [1],\n",
    "}\n",
    "\n",
    "output_directory = os.path.join(data_dir, \"input_files\")\n",
    "scenario = \"1\"\n",
    "\n",
    "# the number of samples you wish to generate\n",
    "n_samples = 1\n",
    "\n",
    "# seed value for reproducibility if so desired\n",
    "seed_value = 1\n",
    "\n",
    "# number of rows to skip in file after comment\n",
    "skip_rows = 0\n",
    "\n",
    "# name of field to query\n",
    "query_field = \"struct\"\n",
    "\n",
    "# number of jobs to launch in parallel; -1 is all but 1 processor used\n",
    "n_jobs = -1\n",
    "\n",
    "# basin to process\n",
    "basin_name = \"San_Juan\"\n",
    "\n",
    "# generate a batch of files using generated LHS\n",
    "stm.modify_ddr(modify_dict=setup_dict,\n",
    "               query_field=query_field,\n",
    "               output_dir=output_directory,\n",
    "               scenario=scenario,\n",
    "               basin_name=basin_name,\n",
    "               sampling_method=\"LHS\",\n",
    "               n_samples=n_samples,\n",
    "               skip_rows=skip_rows,\n",
    "               n_jobs=n_jobs,\n",
    "               seed_value=seed_value,\n",
    "               template_file=None,\n",
    "               factor_method=\"multiply\",\n",
    "               data_specification_file=None,\n",
    "               min_bound_value=-0.5,\n",
    "               max_bound_value=1.5,\n",
    "               save_sample=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b10d2a-30e0-424e-b330-4f7cbb01b38b",
   "metadata": {},
   "source": [
    "In the `input_files` directory, you can open the `sj2015B_S0_1.ddr` file and see that the Admin # of our selected user has now become 1.0000. Now we rerun our code to do the StateMod simulation, this time using the .`ddr` template file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb6d099-8aa4-4d52-b5ee-94ab8a254d4a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set realization and sample\n",
    "realization = 1\n",
    "sample = np.arange(0, 1, 1)\n",
    "\n",
    "# read RSP template\n",
    "with open(ddr_template_file) as template_obj:\n",
    "    \n",
    "    # read in file\n",
    "    template_rsp = Template(template_obj.read())\n",
    "\n",
    "    for i in sample:\n",
    "        \n",
    "        # create scenario name\n",
    "        scenario = f\"S{i}_{realization}\"\n",
    "        \n",
    "        # dictionary holding search keys and replacement values to update the template file\n",
    "        d = {\"DDR\": f\"../../input_files/sj2015B_{scenario}.ddr\"}\n",
    "        \n",
    "        # update the template\n",
    "        new_rsp = template_rsp.safe_substitute(d)\n",
    "        \n",
    "        # construct simulated scenario directory\n",
    "        simulated_scenario_dir = os.path.join(scenarios_dir_ddr, scenario)\n",
    "        if not os.path.exists(simulated_scenario_dir):\n",
    "            os.makedirs(simulated_scenario_dir)\n",
    "            \n",
    "        # target rsp file\n",
    "        rsp_file = os.path.join(simulated_scenario_dir, f\"sj2015B_{scenario}.rsp\")\n",
    "        \n",
    "        # write updated rsp file\n",
    "        with open(rsp_file, \"w\") as f1:\n",
    "            f1.write(new_rsp)\n",
    "        \n",
    "        # construct simulated basin path\n",
    "        simulated_basin_path = os.path.join(simulated_scenario_dir, f\"sj2015B_{scenario}\")\n",
    "\n",
    "        # run StateMod\n",
    "        print(f\"Running: {scenario}\")\n",
    "        os.chdir(simulated_scenario_dir)\n",
    "\n",
    "        subprocess.call([statemod_exe, simulated_basin_path, \"-simulate\"])\n",
    "        \n",
    "        #Save output to parquet files \n",
    "        print('creating parquet for ' + scenario)\n",
    "        \n",
    "        output_directory = os.path.join(parquet_dir_ddr+\"/scenario/\"+ scenario)\n",
    "        \n",
    "        if not os.path.exists(output_directory):\n",
    "            os.makedirs(output_directory)\n",
    "        \n",
    "        stm.xdd.convert_xdd(output_path=output_directory,allow_overwrite=False,xdd_files=scenarios_dir_ddr + \"/\"+ scenario + \"/sj2015B_\"+scenario+\".xdd\",id_subset=['2900501'],parallel_jobs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26aeb572-a614-4778-b692-bd788e3f8423",
   "metadata": {},
   "source": [
    "As before, let's go ahead and plot the shortages for our User 2900501 with respect to the baseline shortages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00fc3c1-cfda-465f-9220-8cc884cb05fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Read in raw parquet files\n",
    "baseline=pd.read_parquet(data_dir+'/historic_shortages/sj2015B.parquet',engine='pyarrow')\n",
    "SOW_1=pd.read_parquet(parquet_dir_ddr+ '/scenario/S0_1/sj2015B_S0_1.parquet',engine='pyarrow')\n",
    "\n",
    "#Subtract shortages with respect to the baseline\n",
    "subset_df=pd.concat([baseline['year'],baseline['shortage_total'],SOW_1['shortage_total']],axis=1)\n",
    "subset_df = subset_df.set_axis(['Year', 'Baseline', 'SOW_1'], axis=1)\n",
    "subset_df['Baseline']=subset_df['Baseline'].astype(float)\n",
    "subset_df['SOW_1']=subset_df['SOW_1'].astype(float)\n",
    "subset_df['Year']=subset_df['Year'].astype(int)\n",
    "subset_df['diff']=subset_df['SOW_1']-subset_df['Baseline']\n",
    "\n",
    "#Plot shortages\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.scatter(subset_df['Year'], subset_df['diff'])\n",
    "\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Shortage (AF)\")\n",
    "plt.title(\"Change in Shortages from the Baseline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c60960-465a-4059-ac54-74ccafcfcdca",
   "metadata": {},
   "source": [
    "We generally see the behavior we expect to see which is that with more senior water rights, the user sees a decrease in shortage magnitude. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd68d814-eda4-415c-9c38-2e383ff1eaaf",
   "metadata": {},
   "source": [
    "Now, continue on to Quickstarter Notebook #2 to learn how to use the reservoir evaporation modification fuction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90af3f9",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\"> \n",
    "    \n",
    "<b>Tip:</b> If you are interested in understanding how to apply `statemodify` functions to your own model, take a look at the source code found in the repository here:   \n",
    "    \n",
    "    \n",
    "<div>\n",
    "    1.  <a href=\"https://github.com/IMMM-SFA/statemodify/blob/main/statemodify/ddm.py\">modify_ddm()</a>\n",
    "\n",
    "</div> \n",
    "\n",
    "<div>\n",
    "    2.  <a href=\"https://github.com/IMMM-SFA/statemodify/blob/main/statemodify/ddr.py\">modify_ddr()</a>\n",
    "\n",
    "</div> \n",
    "  \n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8a0c57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
