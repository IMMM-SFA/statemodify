{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa785565-359c-4a30-a277-144b675d5985",
   "metadata": {},
   "source": [
    "## `statemodify` Quickstarter Notebook #3 : Using the RES Modification Function in the Upper Colorado River Basin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bccd59-5e9a-4639-8d00-fcd507e2ef6d",
   "metadata": {},
   "source": [
    "This notebook demonstrates the reservoir storage modification function in the Upper Colorado River Basin. In this notebook, we seek to understand how changes to reservoir storage can impact user shortages. First we run a baseline simulation, which runs the StateMod simulation assuming that the current infrastructure has existed through the whole simulation period. We next extract shortages for a municipality. Recall that the list of users and their water rights can be found in the `.ddr` file (located: `data/cm2015_StateMod/StateMod/cm2015.ddr`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd25385-8ea8-4dda-ae47-9f23f096f26e",
   "metadata": {},
   "source": [
    "### Step 1: Run a Historical Simulation in StateMod for the Uppper Colorado Subbasin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46286883-98cc-4c5b-94a2-86de7f92449e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import pickle\n",
    "import subprocess\n",
    "from string import Template\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import statemodify as stm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53074387-6935-497e-89a0-a35275d253f3",
   "metadata": {},
   "source": [
    "As before, we set the directories and associated paths and also run StateMod in a baseline simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2ddfdd-15db-4bc4-a7eb-98b136f6adf9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# statemod directory\n",
    "statemod_dir = \"/usr/src/statemodify/statemod_upper_co\"\n",
    "\n",
    "# root directory of statemod data for the target basin\n",
    "root_dir = os.path.join(statemod_dir, \"src\", \"main\", \"fortran\")\n",
    "\n",
    "# home directory of notebook instance\n",
    "home_dir = os.path.dirname(os.getcwd())\n",
    "\n",
    "# path to the statemod executable\n",
    "statemod_exe = os.path.join(root_dir, \"statemod\")\n",
    "\n",
    "# data directory and root name for the target basin\n",
    "data_dir = os.path.join(home_dir, \"data\", \"cm2015_StateMod\", \"StateMod\")\n",
    "\n",
    "# directory to the target basin input files with root name for the basin\n",
    "basin_path = os.path.join(data_dir, \"cm2015B\")\n",
    "\n",
    "# scenarios output directory\n",
    "scenarios_dir_res = os.path.join(data_dir, \"scenarios_res\")\n",
    "\n",
    "# parquet files output directory\n",
    "parquet_dir_res = os.path.join(data_dir, \"parquet_res\")\n",
    "\n",
    "\n",
    "# path to res template file\n",
    "res_template_file = os.path.join(home_dir, \"data\", \"cm2015B_template_res.rsp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5678df-0b96-4184-9c77-2b737e638669",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> <b>NOTE</b> In order to expedite simulations for the Upper Colorado dataset, make sure to turn off \"Reoperation\" mode. You can do so by opening `data/cm2015_StateMod/StateMod/cm2015.ctl`, navigating to the `ireopx` entry and changing the value from \"0\" to \"10\".  </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86d0e12-515a-4af5-94b6-0297b468de2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Change directories first\n",
    "os.chdir(\n",
    "    data_dir\n",
    ")  # This is needed specific to the Upper Colorado model as the path name is too long for the model to accept\n",
    "subprocess.call([statemod_exe, \"cm2015B\", \"-simulate\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e970f6-af43-454e-8aed-af3d8afb6730",
   "metadata": {
    "tags": []
   },
   "source": [
    "We isolate the shortages for one municipal user: the Town of Brekenridge at the base of the Rocky Mountains’ Tenmile Range (ID: 3601008). If we look up this user in the `cm2015B.ddr` file, we see that the user has median water rights (47483.00000) and a smaller decree of 2.90 cfs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0758c26d-9690-4bc5-869a-73feed2b9126",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract shortages using statemodify convert_xdd() function\n",
    "\n",
    "# create a directory to store the historic shortages\n",
    "output_dir = os.path.join(data_dir, \"historic_shortages\")\n",
    "\n",
    "# create a directory to store the new files in if it does not exist\n",
    "output_directory = os.path.join(data_dir, \"historic_shortages\")\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "stm.xdd.convert_xdd(\n",
    "    # path to a directory where output .parquet files should be written\n",
    "    output_path=output_dir,\n",
    "    # whether to abort if .parquet files already exist at the output_path\n",
    "    allow_overwrite=True,\n",
    "    # path, glob, or a list of paths/globs to the .xdd files you want to convert\n",
    "    xdd_files=os.path.join(data_dir, \"*.xdd\"),\n",
    "    # if the output .parquet files should only contain a subset of structure ids, list them here; None for all\n",
    "    id_subset=[\"3601008\"],\n",
    "    # how many .xdd files to convert in parallel; optimally you will want 2-4 CPUs per parallel process\n",
    "    parallel_jobs=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e5313b-feb6-4e8c-9273-7b0c6dfd335e",
   "metadata": {},
   "source": [
    "Next we plot the shortages for Breckenridge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d66198-db40-4874-8cb5-61b1d1346240",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_parquet(output_dir + \"/cm2015B.parquet\", engine=\"pyarrow\")\n",
    "\n",
    "\n",
    "data[\"shortage_total\"] = data[\"shortage_total\"].astype(float)\n",
    "data[\"year\"] = data[\"year\"].astype(int)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for name, group in data.groupby(\"structure_id\"):\n",
    "    ax.scatter(group[\"year\"], group[\"shortage_total\"], label=name)\n",
    "\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Shortage (AF)\")\n",
    "plt.title(\"Baseline Shortages for Breckenridge\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03d4b00-5556-4790-9834-9f4a3bd98074",
   "metadata": {},
   "source": [
    "We see that Breckenridge has experienced a variety of shortages throughout the baseline simulation period."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce887e9-2f3e-4810-8b25-c127f7abd411",
   "metadata": {},
   "source": [
    "### Step 2: Modify StateMod Input Files for Exploratory Analyses- Reservoir Function Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2689a64a-07f8-4d0d-aaab-a8fc1ecc0624",
   "metadata": {},
   "source": [
    "If we look at the `cm2015B.res` file, we see that Breckenridge has an account in the Clinton Gulch Reservoir, but a quick look in the `.opr` file also indicates that Breckenridge can receive water from the Dillon reservoir. Let’s investigate what happens to these shortages when storage at these two basins decreases using the `modify_res()` function. As done in Hadjimichael et al. (2020), we sample losses of up to 20% of the capacity of the reservoirs (informed by Graf et al. (2010)) which may be due to erosion and sedimentation of reservoirs in the UCRB, resulting in reduced storage. The accounts associated with the reservoirs are also reduced equally in order to accommodate the new storage level. For this example, we want to change the reservoir storage for a specific set of reservoirs by specifying the reservoir IDs for the `target_structure_id_list`. However, by setting `target_structure_id_list=None` we can decrease storage at all reservoirs in the basin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc08da33-396c-443b-b6ff-dadbc7a1fae3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_directory = output_dir = os.path.join(data_dir, \"input_files\")\n",
    "scenario = \"1\"\n",
    "# basin name to process\n",
    "basin_name = \"Upper_Colorado\"\n",
    "\n",
    "# seed value for reproducibility if so desired\n",
    "seed_value = 1\n",
    "\n",
    "# number of jobs to launch in parallel; -1 is all but 1 processor used\n",
    "n_jobs = 2\n",
    "\n",
    "# number of samples to generate\n",
    "n_samples = 1\n",
    "\n",
    "stm.modify_res(\n",
    "    output_dir=output_directory,\n",
    "    scenario=scenario,\n",
    "    basin_name=basin_name,\n",
    "    target_structure_id_list=[\"3603575\", \"3604512\"],\n",
    "    seed_value=seed_value,\n",
    "    n_jobs=n_jobs,\n",
    "    n_samples=n_samples,\n",
    "    save_sample=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01594000-7850-4fe0-961b-7bb822db912f",
   "metadata": {},
   "source": [
    "Since we are sampling only reductions in storage, we can investigate behavior with a single sample. We can then load the saved sample to see the percent reduction in reservoir storage volume that has been applied to the different reservoirs. The sample indicates that we are reducing the reservoir storage volume to 86% of the original storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b67e22-69ff-46ce-9f1d-a4d6c01f71d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "sample_array = np.load(output_directory + \"/res_1-samples_scenario-1.npy\")\n",
    "sample_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b84276-dbeb-4715-b3f0-6f5b6fb08e05",
   "metadata": {},
   "source": [
    "### Step 3: Read in the New Input Files and Run StateMod : Reservoir Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc992b38-ef4b-4947-b49f-3b5d7d27a3b9",
   "metadata": {},
   "source": [
    "Now that we have created the input files, the next step is to run StateMod with the new input files. We create a template `.rsp` file (`cm2015B_template_res.rsp`) and swap in the path to the alternative `.res` files that are created. Then we run StateMod for the two scenarios and extract the shortages for Breckenridge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaaec47d-0a39-4c7b-b8ed-54156d251a1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set realization and sample\n",
    "realization = 1\n",
    "sample = np.arange(0, 2, 1)\n",
    "\n",
    "# read RSP template\n",
    "with open(res_template_file) as template_obj:\n",
    "    # read in file\n",
    "    template_rsp = Template(template_obj.read())\n",
    "\n",
    "    for i in sample:\n",
    "        # create scenario name\n",
    "        scenario = f\"S{i}_{realization}\"\n",
    "\n",
    "        # dictionary holding search keys and replacement values to update the template file\n",
    "        d = {\"RES\": f\"../../input_files/cm2015B_{scenario}.res\"}\n",
    "\n",
    "        # update the template\n",
    "        new_rsp = template_rsp.safe_substitute(d)\n",
    "\n",
    "        # construct simulated scenario directory\n",
    "        simulated_scenario_dir = os.path.join(scenarios_dir_res, scenario)\n",
    "        if not os.path.exists(simulated_scenario_dir):\n",
    "            os.makedirs(simulated_scenario_dir)\n",
    "\n",
    "        # target rsp file\n",
    "        rsp_file = os.path.join(simulated_scenario_dir, f\"cm2015B_{scenario}.rsp\")\n",
    "\n",
    "        # write updated rsp file\n",
    "        with open(rsp_file, \"w\") as f1:\n",
    "            f1.write(new_rsp)\n",
    "\n",
    "        # construct simulated basin path\n",
    "        simulated_basin_path = f\"cm2015B_{scenario}\"\n",
    "\n",
    "        # run StateMod\n",
    "        print(f\"Running: {scenario}\")\n",
    "        os.chdir(simulated_scenario_dir)\n",
    "\n",
    "        subprocess.call([statemod_exe, simulated_basin_path, \"-simulate\"])\n",
    "\n",
    "        # Save output to parquet files\n",
    "        print(\"creating parquet for \" + scenario)\n",
    "\n",
    "        output_directory = os.path.join(parquet_dir_res + \"/scenario/\" + scenario)\n",
    "\n",
    "        if not os.path.exists(output_directory):\n",
    "            os.makedirs(output_directory)\n",
    "\n",
    "        stm.xdd.convert_xdd(\n",
    "            output_path=output_directory,\n",
    "            allow_overwrite=True,\n",
    "            xdd_files=scenarios_dir_res\n",
    "            + \"/\"\n",
    "            + scenario\n",
    "            + \"/cm2015B_\"\n",
    "            + scenario\n",
    "            + \".xdd\",\n",
    "            id_subset=[\"3601008\"],\n",
    "            parallel_jobs=2,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d199d2-bf7c-49d9-adc9-8616aa910c49",
   "metadata": {},
   "source": [
    "Here, we extract the shortages from the Parquet files for the baseline and alternative states of the world and plot the resulting shortages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a991e2-7e76-4e96-b4c0-70a641e66de3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "baseline = pd.read_parquet(\n",
    "    data_dir + \"/\" + \"historic_shortages/cm2015B.parquet\", engine=\"pyarrow\"\n",
    ")\n",
    "SOW_1 = pd.read_parquet(\n",
    "    parquet_dir_res + \"/scenario/S0_1/cm2015B_S0_1.parquet\", engine=\"pyarrow\"\n",
    ")\n",
    "\n",
    "# Subtract shortages with respect to the baseline\n",
    "subset_df = pd.concat(\n",
    "    [baseline[\"year\"], baseline[\"shortage_total\"], SOW_1[\"shortage_total\"]], axis=1\n",
    ")\n",
    "subset_df = subset_df.set_axis([\"Year\", \"Baseline\", \"SOW_1\"], axis=1)\n",
    "subset_df[\"Baseline\"] = subset_df[\"Baseline\"].astype(float)\n",
    "subset_df[\"SOW_1\"] = subset_df[\"SOW_1\"].astype(float)\n",
    "subset_df[\"Year\"] = subset_df[\"Year\"].astype(int)\n",
    "subset_df[\"SOW_1_diff\"] = subset_df[\"SOW_1\"] - subset_df[\"Baseline\"]\n",
    "\n",
    "# Plot shortages\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.scatter(subset_df[\"Year\"], subset_df[\"SOW_1_diff\"])\n",
    "\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Shortage (AF)\")\n",
    "plt.title(\"Change in Breckenridge Shortages from the Baseline\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b7564c-1600-4b8c-99f6-b9995e0a110b",
   "metadata": {},
   "source": [
    "When we plot the shortages to Breckenridge under the alternative SOW where reservoir storage is reduced across the two reservoirs, we can see that there are now instances in which Breckenridge experiences larger shortages than in the baseline case. Given that the town utilizes both direct diversions and reservoir storage for water supply, this result suggests that they have less of a bank of water to pull from in the two reservoirs which increases shortages. However, there are even some cases where the town experiences surpluses and many cases where the shortages do not change, demonstrating that there is inherent complexity in the mapping of reservoir level to shortages, especially when the user has multiple reservoir accounts. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252c1c2c-2611-4cf7-934f-2d22916f9c76",
   "metadata": {},
   "source": [
    "Now continue on to Quickstarter Notebook #4 to learn about running StateMod with new streamflow scenarios across the West Slope basins."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c20a620-a9db-47ab-8ee8-a8fb3e424a9a",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "Graf, W. L., Wohl, E., Sinha, T., & Sabo, J. L. (2010). Sedimentation and sustainability of western American reservoirs. Water Resources Research, 46, W12535. https://doi.org/10.1029/2009WR008836\n",
    "\n",
    "\n",
    "Hadjimichael, A., Quinn, J., Wilson, E., Reed, P., Basdekas, L., Yates, D., & Garrison, M. (2020). Defining robustness, vulnerabilities, and consequential scenarios for diverse stakeholder interests in institutionally complex river basins. Earth's Future, 8(7), e2020EF001503.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
